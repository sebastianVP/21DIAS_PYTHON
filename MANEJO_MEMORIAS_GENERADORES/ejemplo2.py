""""
control de memoria eficiente, una habilidad clave en an치lisis 
de grandes vol칰menes de datos o logs de sensores.

Ejemplo completo y comentado que muestra c칩mo implementar un generador que
lee un archivo l칤nea por l칤nea sin cargarlo entero en memoria:
"""
def leer_lineas_en_stream(ruta_archivo:str):
    """
    Generado que lee un rachivo linea por linea,
    sin cargarlo completamente en memoria.
    """
    with open(ruta_archivo,"r",encoding="utf-8") as f:
        for linea in f:
            yield linea.strip() ## devolvemos cada linea limpia

ruta= "datos_sensores.txt"
contador =0
for linea in leer_lineas_en_stream(ruta):
    # PROCESAMOS LA LINEA(ejemplo:imprimir las 5 primeras)
    if contador<5:
        print(linea)
    contador +=1
"""
游 Qu칠 est치 pasando aqu칤

La funci칩n leer_lineas_en_stream() no carga el archivo completo en memoria.
En cambio, abre un flujo (with open(...)) y va entregando una l칤nea cada vez
 usando yield.

Cada vez que el bucle for pide una nueva l칤nea, el generador reanuda 
su ejecuci칩n justo donde se qued칩.

Es ideal para archivos de varios GB, donde una lectura completa
con read() o readlines() saturar칤a la RAM.

Aplicaci칩n pr치ctica

Este patr칩n se usa mucho para:

Procesamiento de logs o datasets muy grandes.

Lectura de datos de sensores en tiempo real.

Pipelines ETL o tareas de streaming analytics.

"""
# PARA VER LA DIFERENCIA
import sys

ruta = "datos_sensores.txt"

# Versi칩n 1: lectura completa
with open(ruta, "r", encoding="utf-8") as f:
    lineas = f.readlines()
print("Tama침o en memoria (readlines):", sys.getsizeof(lineas), "bytes")

# Versi칩n 2: lectura por generador
g = leer_lineas_en_stream(ruta)
print("Tama침o en memoria (generador):", sys.getsizeof(g), "bytes")