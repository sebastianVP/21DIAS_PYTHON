"""
pip show langchain-ollama
si no sale el paquete
pip install -U langchain-ollama


"""
# test_ollama.py
from langchain_community.llms import Ollama

# VerificaciÃ³n del modelo
llm = Ollama(model="llama3", temperature=0)

print("âœ… Ollama cargado correctamente con LangChain Community")
print("ðŸ§  Probando generaciÃ³n...")

#respuesta = llm.invoke("Â¿CuÃ¡l es la capital de PerÃº?")
respuesta = llm.invoke("Â¿Alan Garcia dio un discurso en el 2008?")

print("ðŸ’¬ Respuesta:", respuesta)