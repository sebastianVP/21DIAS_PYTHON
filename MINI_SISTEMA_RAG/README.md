# ** ğŸ§­QDRANTâ€“LANGCHAIN BOOTCAMP**

## **Objetivo**: 

Construir un mini sistema RAG (Retrieval Augmented Generation) desde cero, entendiendo cada capa:
embeddings â†’ indexaciÃ³n HNSW â†’ almacenamiento vectorial â†’ consulta semÃ¡ntica â†’ respuesta con LLM.

NOTA: ğŸ”¹ HNSW (Hierarchical Navigable Small World)

**Comprender el flujo general y tener todo el entorno listo (local o nube).**

1.1 Concepto mental del pipeline RAG
Texto â†’ Embedding â†’ Base Vectorial (Qdrant/HNSW) â†’ LangChain â†’ LLM â†’ Respuesta contextual

ğŸ§© **ExplicaciÃ³n rÃ¡pida:**

- Cada documento se transforma en un vector numÃ©rico (embedding).
- Qdrant guarda esos vectores y usa HNSW para encontrar los mÃ¡s parecidos.
- LangChain coordina la bÃºsqueda y genera la respuesta final con un LLM (OpenAI o local).

1.2 InstalaciÃ³n rÃ¡pida (en tu entorno con Python)

Abre tu terminal y ejecuta:

pip install qdrant-client langchain sentence-transformers openai
pip install fastapi uvicorn # opcional si luego deseas servirlo vÃ­a API

Si usarÃ¡s Qdrant local:

docker run -p 6333:6333 qdrant/qdrant


Verifica que estÃ¡ activo en:
ğŸ‘‰ http://localhost:6333/dashboard

Si prefieres la nube:

Crea una cuenta en https://cloud.qdrant.io

Crea un cluster gratuito.

ObtÃ©n tu API Key y URL endpoint.